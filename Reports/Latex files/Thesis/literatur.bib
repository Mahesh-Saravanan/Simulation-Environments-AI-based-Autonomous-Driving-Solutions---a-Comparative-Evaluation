@misc{sae2019,
  title = {{SAE} Updates {J3016} Automated Driving Graphic},
  howpublished = {\url{https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic}},
  note = {Accessed on [17.11.2023]},
}
@inproceedings{Carla,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}
@inproceedings{lgsvl,
  title={Lgsvl simulator: A high fidelity simulator for autonomous driving},
  author={Rong, Guodong and Shin, Byung Hyun and Tabatabaee, Hadi and Lu, Qiang and Lemke, Steve and Mo{\v{z}}eiko, M{\=a}rti{\c{n}}{\v{s}} and Boise, Eric and Uhm, Geehoon and Gerow, Mark and Mehta, Shalin and others},
  booktitle={2020 IEEE 23rd International conference on intelligent transportation systems (ITSC)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}
@INPROCEEDINGS{SUMMIT,
  author={Cai, Panpan and Lee, Yiyuan and Luo, Yuanfu and Hsu, David},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic}, 
  year={2020},
  volume={},
  number={},
  pages={4023-4029},
  doi={10.1109/ICRA40945.2020.9197228}}
@inproceedings{yangsurvey,
  title={Survey on autonomous vehicle simulation platforms},
  author={Yang, Guang and Xue, Yunzhi and Meng, Lingzhong and Wang, Pengqi and Shi, Yuan and Yang, Qinghong and Dong, Qian},
  booktitle={2021 8th International Conference on Dependable Systems and Their Applications (DSA)},
  pages={692--699},
  year={2021},
  organization={IEEE}
}
@inproceedings{Ahmedsurvey,
  title={Comparative study of connected vehicle simulators},
  author={Ahmed, Md Salman and Hoque, Mohammad Asadul and Pfeiffer, Phil},
  booktitle={SoutheastCon 2016},
  pages={1--7},
  year={2016},
  organization={IEEE}
}
@article{7_gan,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}
@article{8_Vgan,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@inproceedings{9_imaginator,
  title={Imaginator: Conditional spatio-temporal gan for video generation},
  author={Wang, Yaohui and Bilinski, Piotr and Bremond, Francois and Dantcheva, Antitza},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1160--1169},
  year={2020}
}
@inproceedings{10_mocogan,
  title={Mocogan: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1526--1535},
  year={2018}
}
@inproceedings{11_image2_image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}
@article{12_pix2pix,
  title={Pix2Pix GAN for Image-to-Image Translation},
  author={Henry, Joyce and Natalie, Terry and Madsen, Den},
  journal={Research Gate Publication},
  pages={1--5},
  year={2021}
}
@inproceedings{13_MUG,
  title={The MUG facial expression database},
  author={Aifanti, Niki and Papachristou, Christos and Delopoulos, Anastasios},
  booktitle={11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10},
  pages={1--4},
  year={2010},
  organization={IEEE}
}
@inproceedings{14_aircraft,
  title={Tracking body and hands for gesture recognition: Natops aircraft handling signals database},
  author={Song, Yale and Demirdjian, David and Davis, Randall},
  booktitle={2011 IEEE International Conference on Automatic Face \& Gesture Recognition (FG)},
  pages={500--506},
  year={2011},
  organization={IEEE}
}
@book{15_act_rec,
  title={Action recognition from a small number of frames},
  author={Mauthner, Thomas and Roth, Peter M and Bischof, Horst},
  year={2009},
  publisher={na}
}
@inproceedings{16_face,
  title={Face recognition using dynamic features extracted from smile videos},
  author={Taskirar, Murat and Killioglu, Mehmet and Kahraman, Nihan and Erdem, Cigdem Eroglu},
  booktitle={2019 IEEE International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}
@inproceedings{17_taichi,
  title={Taichi: A fine-grained action recognition dataset},
  author={Sun, Shan and Wang, Feng and Liang, Qi and He, Liang},
  booktitle={Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval},
  pages={429--433},
  year={2017}
}
@inproceedings{18_Waymo,
  title={Scalability in perception for autonomous driving: Waymo open dataset},
  author={Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2446--2454},
  year={2020}
}
@article{19_audi,
  title={A2d2: Audi autonomous driving dataset},
  author={Geyer, Jakob and Kassahun, Yohannes and Mahmudi, Mentar and Ricou, Xavier and Durgesh, Rupesh and Chung, Andrew S and Hauswald, Lorenz and Pham, Viet Hoang and M{\"u}hlegg, Maximilian and Dorn, Sebastian and others},
  journal={arXiv preprint arXiv:2004.06320},
  year={2020}
}
@inproceedings{20_cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3213--3223},
  year={2016}
}
@inproceedings{21_panda,
  title={Pandaset: Advanced sensor suite dataset for autonomous driving},
  author={Xiao, Pengchuan and Shao, Zhenlei and Hao, Steven and Zhang, Zishuo and Chai, Xiaolin and Jiao, Judy and Li, Zesong and Wu, Jian and Sun, Kai and Jiang, Kun and others},
  booktitle={2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
  pages={3095--3101},
  year={2021},
  organization={IEEE}
}
@article{tgan,
  title={Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan},
  author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
  journal={International Journal of Computer Vision},
  volume={128},
  number={10-11},
  pages={2586--2606},
  year={2020},
  publisher={Springer}
}
@Article{senimage,
AUTHOR = {Kumar, G Ajay and Lee, Jin Hee and Hwang, Jongrak and Park, Jaehyeong and Youn, Sung Hoon and Kwon, Soon},
TITLE = {LiDAR and Camera Fusion Approach for Object Distance Estimation in Self-Driving Vehicles},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {324},
URL = {https://www.mdpi.com/2073-8994/12/2/324},
ISSN = {2073-8994},
ABSTRACT = {The fusion of light detection and ranging (LiDAR) and camera data in real-time is known to be a crucial process in many applications, such as in autonomous driving, industrial automation, and robotics. Especially in the case of autonomous vehicles, the efficient fusion of data from these two types of sensors is important to enabling the depth of objects as well as the detection of objects at short and long distances. As both the sensors are capable of capturing the different attributes of the environment simultaneously, the integration of those attributes with an efficient fusion approach greatly benefits the reliable and consistent perception of the environment. This paper presents a method to estimate the distance (depth) between a self-driving car and other vehicles, objects, and signboards on its path using the accurate fusion approach. Based on the geometrical transformation and projection, low-level sensor fusion was performed between a camera and LiDAR using a 3D marker. Further, the fusion information is utilized to estimate the distance of objects detected by the RefineDet detector. Finally, the accuracy and performance of the sensor fusion and distance estimation approach were evaluated in terms of quantitative and qualitative analysis by considering real road and simulation environment scenarios. Thus the proposed low-level sensor fusion, based on the computational geometric transformation and projection for object distance estimation proves to be a promising solution for enabling reliable and consistent environment perception ability for autonomous vehicles.},
DOI = {10.3390/sym12020324}
}

@article{activation,
author = {Jin, Rui and Niu, Qiang},
year = {2021},
month = {09},
pages = {1-13},
title = {Automatic Fabric Defect Detection Based on an Improved YOLOv5},
volume = {2021},
journal = {Mathematical Problems in Engineering},
doi = {10.1155/2021/7321394}
}
@inproceedings{Gazebobase,
  title={Design and use paradigms for gazebo, an open-source multi-robot simulator},
  author={Koenig, Nathan and Howard, Andrew},
  booktitle={2004 IEEE/RSJ international conference on intelligent robots and systems (IROS)(IEEE Cat. No. 04CH37566)},
  volume={3},
  pages={2149--2154},
  year={2004},
  organization={IEEE}
}
@misc{opende,
  title = {{Open Dynamics Engine}},
  author = {{Open Dynamics Engine}},
  howpublished = {\url{https://opende.sourceforge.net/}},
  year = {Accessed: 2023}
}
@inproceedings{golf,
  title={Golf cart prototype development and navigation simulation using ROS and Gazebo},
  author={Shimchik, Ilya and Sagitov, Artur and Afanasyev, Ilya and Matsuno, Fumitoshi and Magid, Evgeni},
  booktitle={MATEC Web of Conferences},
  volume={75},
  pages={09005},
  year={2016},
  organization={EDP Sciences}
}
@misc{opengl,
  title = {{OpenGL}},
  author = {{The Khronos Group}},
  howpublished = {\url{https://www.opengl.org/}},
  year = {Accessed: 2023}
}
@article{torcs,
  title={Torcs, the open racing car simulator},
  author={Wymann, Bernhard and Espi{\'e}, Eric and Guionneau, Christophe and Dimitrakakis, Christos and Coulom, R{\'e}mi and Sumner, Andrew},
  journal={Software available at http://torcs. sourceforge. net},
  volume={4},
  number={6},
  pages={2},
  year={2000}
}
@inproceedings{rvgan,
  title={Rv-gan: Recurrent gan for unconditional video generation},
  author={Gupta, Sonam and Keshari, Arti and Das, Sukhendu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2024--2033},
  year={2022}
}
@article{fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{UCF,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}
@article{v3gan,
  title={V3GAN: Decomposing Background, Foreground and Motion for Video Generation},
  author={Keshari, Arti and Gupta, Sonam and Das, Sukhendu},
  journal={arXiv preprint arXiv:2203.14074},
  year={2022}
}
@article{weizmann,
  title={Actions as space-time shapes},
  author={Gorelick, Lena and Blank, Moshe and Shechtman, Eli and Irani, Michal and Basri, Ronen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={29},
  number={12},
  pages={2247--2253},
  year={2007},
  publisher={IEEE}
}
@misc{carla-docs,
  title = {{CARLA} Documentation},
  author = {{CARLA Team}},
  howpublished = {\url{https://carla.readthedocs.io/en/latest/}},
  year = {2023}
}
@misc{summit-docs,
  title = {{SUMMIT} Documentation},
  author = {{Summit Team}},
  howpublished = {\url{https://adacompnus.github.io/summit-docs}},
  year = {2023}
}

@misc{lgvsl-docs,
  title = {{LGVSL} Simulator Documentation},
  author = {{LGVSL Team}},
  howpublished = {\url{https://www.svlsimulator.com/docs/}},
  year = {2023}
}
